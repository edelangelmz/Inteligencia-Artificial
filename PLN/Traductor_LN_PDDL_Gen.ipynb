{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCDgwOr2BMVyKvx6Nj6eX1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edelangelmz/Inteligencia-Artificial/blob/main/PLN/Traductor_LN_PDDL_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lectura del dataset"
      ],
      "metadata": {
        "id": "7ZYZSwik5D11"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "Df0NuSN6UEA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64de23ed-e6fb-4df4-b74b-3ee178c41ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/drive/My Drive/Colab Notebooks/Datasets/LN2PDDL.txt'\n",
        "\n",
        "with open(filename) as file:\n",
        "  dataset = file.readlines()\n",
        "\n",
        "  print(len(dataset))\n",
        "  print(dataset[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-akjHeVWY_0A",
        "outputId": "fbf3d362-bdc3-4066-ec09-2dacf2f892d2"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1005\n",
            "ambulancia se encuentra en\tambulancia-en-localizacion\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento de los datos\n",
        "def preprocess_text(text):\n",
        "  text = text.replace('\\n', '')\n",
        "  text = text.replace('á', 'a')\n",
        "  text = text.replace('é', 'e')\n",
        "  text = text.replace('í', 'i')\n",
        "  text = text.replace('ó', 'o')\n",
        "  text = text.replace('ú', 'u')\n",
        "  text = text.replace(',', '')\n",
        "\n",
        "  return text\n",
        "\n",
        "def preprocess_code_input(code):\n",
        "  code = code.replace('\\n', '')\n",
        "  code = code.replace('é', 'e')\n",
        "  code = code.replace('í', 'i')\n",
        "  code = code.replace('ó', 'o')\n",
        "  code = code.replace('á', 'a')\n",
        "  code = code.replace('ú', 'u')\n",
        "  code = code.replace(',', '')\n",
        "  code = code.replace('-', ' - ')\n",
        "  code = code.replace('  ', ' ')\n",
        "\n",
        "  return code\n",
        "\n",
        "def preprocess_code_output(code):\n",
        "  code = code.replace(' - ', '-')\n",
        "  code = code.replace('\\n', '')\n",
        "\n",
        "  return code"
      ],
      "metadata": {
        "id": "iNm9Ck0BLRag"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear 'tokens'\n",
        "source_tokens = []\n",
        "target_tokens = []\n",
        "\n",
        "# Extracción del dataset\n",
        "for element in dataset:\n",
        "  element = element.split('\\t')\n",
        "  element[0] = preprocess_text(element[0])\n",
        "  element[1] = preprocess_code_output(element[1])\n",
        "  source_tokens.append(element[0].split(' '))\n",
        "  target_tokens.append(element[1].split(' '))\n",
        "\n",
        "print(source_tokens[7])\n",
        "print(target_tokens[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t6w-1-phojo",
        "outputId": "f7780623-e513-4c34-ee9e-853a0110421f"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ambulancia', 'se', 'encuentra', 'en']\n",
            "['ambulancia-en-localizacion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_token_dict(token_list):\n",
        "  token_dict = {\n",
        "      '<PAD>': 0,\n",
        "      '<START>': 1,\n",
        "      '<END>': 2\n",
        "  }\n",
        "\n",
        "  for tokens in token_list:\n",
        "    for token in tokens:\n",
        "      if token not in token_dict:\n",
        "        token_dict[token] = len(token_dict)\n",
        "\n",
        "  return token_dict"
      ],
      "metadata": {
        "id": "SYsmp2OLcsGa"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_token_dict = build_token_dict(source_tokens)\n",
        "target_token_dict = build_token_dict(target_tokens)\n",
        "target_token_dict_inv = {v:k for k,v in target_token_dict.items()}\n",
        "\n",
        "#for key, value in target_token_dict.items():\n",
        "#  target_token_dict_inv[value] = key\n",
        "\n",
        "print(source_token_dict)\n",
        "print(target_token_dict)\n",
        "print(target_token_dict_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvRBPn83jLe0",
        "outputId": "96a58057-03b3-4059-e235-352a1e04ed80"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<PAD>': 0, '<START>': 1, '<END>': 2, 'algunos': 3, 'tipos': 4, 'ambulancia': 5, 'esta': 6, 'en': 7, 'una': 8, 'localizacion': 9, 'llena': 10, 'cuando': 11, 'lleva': 12, 'un': 13, 'paciente': 14, 'tiene': 15, 'se': 16, 'encuentra': 17, 'vacia': 18, 'diferentes': 19, 'dos': 20, 'localizaciones': 21, 'pacientes': 22, 'efecto': 23, 'el': 24, 'es': 25, 'que': 26, 'este': 27, 'la': 28, 'actual': 29, 'exista': 30, 'cambie': 31, 'de': 32, 'pasa': 33, 'a': 34, 'estar': 35, 'mueva': 36, 'sera': 37, 'hospital': 38, 'empieza': 39, 'uno': 40, 'localiza': 41, 'movimiento': 42, 'cuatro': 43, 'tres': 44, 'tipo': 45, 'problema': 46, 'existe': 47, 'existen': 48, 'hay': 49, 'localizado': 50, 'sobre': 51, 'abulancia': 52, 'La': 53, 'precondicion': 54, 'debe': 55, 'misma': 56, 'encuentre': 57, 'ubique': 58, 'las': 59, '\"los': 60, 'objetos': 61, 'son': 62, 'y': 63, 'hospital\"': 64, 'los': 65, 'parametros': 66, 'ambulancia\"': 67, 'mover': 68, 'moverse': 69, 'entre': 70, 'mueve': 71, 'no': 72, 'objeto': 73, 'unas': 74, 'puede': 75, 'sen': 76}\n",
            "{'<PAD>': 0, '<START>': 1, '<END>': 2, 'types': 3, 'ambulancia': 4, 'ambulancia-en-localizacion': 5, '?localizacion-localizacion': 6, '?ambulancia-ambulancia': 7, 'llena-ambulancia': 8, '?paciente-paciente': 9, 'ambulancia-vacia': 10, '?localizacion1': 11, '-localizacionocalizacion': 12, '?localizacion2-localizacion': 13, 'paciente1': 14, 'paciente2-paciente': 15, 'effect': 16, '(': 17, 'and': 18, '?localizacion': 19, '?ambulancia': 20, ')': 21, 'paciente-en-localizacion': 22, '?paciente': 23, '?localizacion2': 24, 'ir': 25, 'not': 26, '(and': 27, 'hospital-en': 28, 'localizacion1': 29, 'localizaion4': 30, 'localizacion3': 31, 'localizacion2': 32, 'localizacion4': 33, 'paciente': 34, 'paciente2': 35, 'en': 36, 'hospital1-hospital': 37, 'ambulancia1-ambulancia': 38, 'localizacion4-localizacion': 39, 'hospital': 40, 'hospital-en-localizacion': 41, '': 42, 'ambulancia1': 43, 'localizacion': 44, 'precondition': 45, 'parameters': 46, '?localizacion1-localizacion': 47}\n",
            "{0: '<PAD>', 1: '<START>', 2: '<END>', 3: 'types', 4: 'ambulancia', 5: 'ambulancia-en-localizacion', 6: '?localizacion-localizacion', 7: '?ambulancia-ambulancia', 8: 'llena-ambulancia', 9: '?paciente-paciente', 10: 'ambulancia-vacia', 11: '?localizacion1', 12: '-localizacionocalizacion', 13: '?localizacion2-localizacion', 14: 'paciente1', 15: 'paciente2-paciente', 16: 'effect', 17: '(', 18: 'and', 19: '?localizacion', 20: '?ambulancia', 21: ')', 22: 'paciente-en-localizacion', 23: '?paciente', 24: '?localizacion2', 25: 'ir', 26: 'not', 27: '(and', 28: 'hospital-en', 29: 'localizacion1', 30: 'localizaion4', 31: 'localizacion3', 32: 'localizacion2', 33: 'localizacion4', 34: 'paciente', 35: 'paciente2', 36: 'en', 37: 'hospital1-hospital', 38: 'ambulancia1-ambulancia', 39: 'localizacion4-localizacion', 40: 'hospital', 41: 'hospital-en-localizacion', 42: '', 43: 'ambulancia1', 44: 'localizacion', 45: 'precondition', 46: 'parameters', 47: '?localizacion1-localizacion'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregar <PAD>, <START> y <END> a cada frase del set de entrenamiento\n",
        "encoder_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
        "decoder_tokens = [['<START>'] + tokens + ['<END>'] for tokens in target_tokens]\n",
        "output_tokens = [tokens + ['<END>'] for tokens in target_tokens]\n",
        "\n",
        "#encoder_tokens = []\n",
        "#for tokens in source_tokens:\n",
        "#  encoder_tokens.append(['<START>'] + tokens + ['<END>'])\n",
        "\n",
        "source_max_len = max(map(len, encoder_tokens))\n",
        "target_max_len = max(map(len, decoder_tokens))\n",
        "\n",
        "encoder_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encoder_tokens]\n",
        "decoder_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in decoder_tokens]\n",
        "output_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in output_tokens]\n",
        "\n",
        "print(encoder_tokens[120])\n",
        "print(decoder_tokens[120])\n",
        "print(output_tokens[120])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAduHZKqBZ6W",
        "outputId": "8e3f8b38-12c8-4a1e-b5ec-7929e8848cae"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<START>', 'paciente', 'dos', 'esta', 'en', 'la', 'localizacion', 'cuatro', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['<START>', 'paciente-en-localizacion', 'localizacion4', 'paciente2', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "['paciente-en-localizacion', 'localizacion4', 'paciente2', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encoder_tokens]\n",
        "decoder_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decoder_tokens]\n",
        "output_input = [list(map(lambda x: [target_token_dict[x]], tokens)) for tokens in output_tokens]\n",
        "\n",
        "#encoder_input = []\n",
        "#for tokens in encoder_tokens:\n",
        "#  temp = []\n",
        "#  for token in tokens:\n",
        "#    temp.append(source_token_dict[token])\n",
        "#  encoder_input.append(temp)\n",
        "\n",
        "print(encoder_input[120])\n",
        "print(decoder_input[120])\n",
        "print(output_input[120])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmPgWhX8NdpB",
        "outputId": "88fa3c46-c3e2-4748-cb78-ed29a2961d80"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 20, 6, 7, 28, 9, 43, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 22, 33, 35, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[[22], [33], [35], [2], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_transformer"
      ],
      "metadata": {
        "id": "LDAOegx3TXrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5dfca0-a17a-41bc-9418-2e37764f09b1"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_transformer in /usr/local/lib/python3.7/dist-packages (0.40.0)\n",
            "Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.7/dist-packages (from keras_transformer) (0.16.0)\n",
            "Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.7/dist-packages (from keras_transformer) (0.13.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.7/dist-packages (from keras_transformer) (0.8.0)\n",
            "Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.7/dist-packages (from keras_transformer) (0.10.0)\n",
            "Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.7/dist-packages (from keras_transformer) (0.29.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-embed-sim==0.10.0->keras_transformer) (1.21.6)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head==0.29.0->keras_transformer) (0.51.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la red neuronal\n",
        "from keras_transformer import get_model, decode\n",
        "import numpy as np\n",
        "\n",
        "# Establecer una semilla inicial\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "ZhK7eUi5TX8I"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(\n",
        "    token_num = max(len(source_token_dict), len(target_token_dict)),\n",
        "    embed_dim = 32,\n",
        "    encoder_num = 2,\n",
        "    decoder_num = 2,\n",
        "    head_num = 4,\n",
        "    hidden_dim = 128,\n",
        "    dropout_rate = 0.02,\n",
        "    use_same_embed = False\n",
        ")\n",
        "\n",
        "model.compile('adam', 'sparse_categorical_crossentropy')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rwJbL7z0TYL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c4016b-9207-4bc3-e26d-11d574d8ea59"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Encoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Encoder-Token-Embedding (Embed  [(None, None, 32),  2464        ['Encoder-Input[0][0]']          \n",
            " dingRet)                        (77, 32)]                                                        \n",
            "                                                                                                  \n",
            " Encoder-Embedding (TrigPosEmbe  (None, None, 32)    0           ['Encoder-Token-Embedding[0][0]']\n",
            " dding)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Encoder-Embedding[0][0]']      \n",
            " on (MultiHeadAttention)                                                                          \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-Embedding[0][0]',      \n",
            " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    64          ['Encoder-1-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward (FeedFor  (None, None, 32)    8352        ['Encoder-1-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Dropout   (None, None, 32)    0           ['Encoder-1-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Add (Add  (None, None, 32)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Norm (La  (None, None, 32)    64          ['Encoder-1-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Encoder-1-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Decoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Decoder-Token-Embedding (Embed  [(None, None, 32),  2464        ['Decoder-Input[0][0]']          \n",
            " dingRet)                        (77, 32)]                                                        \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-1-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Decoder-Embedding (TrigPosEmbe  (None, None, 32)    0           ['Decoder-Token-Embedding[0][0]']\n",
            " dding)                                                                                           \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    64          ['Encoder-2-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Decoder-Embedding[0][0]']      \n",
            " on (MultiHeadAttention)                                                                          \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward (FeedFor  (None, None, 32)    8352        ['Encoder-2-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-1-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Dropout   (None, None, 32)    0           ['Encoder-2-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-Embedding[0][0]',      \n",
            " on-Add (Add)                                                     'Decoder-1-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Add (Add  (None, None, 32)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    64          ['Decoder-1-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Norm (La  (None, None, 32)    64          ['Encoder-2-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    4224        ['Decoder-1-MultiHeadSelfAttentio\n",
            " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-1-MultiHeadQueryAttenti\n",
            " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
            "                                                                                                  \n",
            " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-1-MultiHeadSelfAttentio\n",
            " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
            "                                                                  'Decoder-1-MultiHeadQueryAttenti\n",
            "                                                                 on-Dropout[0][0]']               \n",
            "                                                                                                  \n",
            " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    64          ['Decoder-1-MultiHeadQueryAttenti\n",
            " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
            "                                                                                                  \n",
            " Decoder-1-FeedForward (FeedFor  (None, None, 32)    8352        ['Decoder-1-MultiHeadQueryAttenti\n",
            " ward)                                                           on-Norm[0][0]']                  \n",
            "                                                                                                  \n",
            " Decoder-1-FeedForward-Dropout   (None, None, 32)    0           ['Decoder-1-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Decoder-1-FeedForward-Add (Add  (None, None, 32)    0           ['Decoder-1-MultiHeadQueryAttenti\n",
            " )                                                               on-Norm[0][0]',                  \n",
            "                                                                  'Decoder-1-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Decoder-1-FeedForward-Norm (La  (None, None, 32)    64          ['Decoder-1-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Decoder-1-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-2-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-1-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Decoder-2-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    64          ['Decoder-2-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    4224        ['Decoder-2-MultiHeadSelfAttentio\n",
            " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-2-MultiHeadQueryAttenti\n",
            " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
            "                                                                                                  \n",
            " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-2-MultiHeadSelfAttentio\n",
            " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
            "                                                                  'Decoder-2-MultiHeadQueryAttenti\n",
            "                                                                 on-Dropout[0][0]']               \n",
            "                                                                                                  \n",
            " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    64          ['Decoder-2-MultiHeadQueryAttenti\n",
            " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
            "                                                                                                  \n",
            " Decoder-2-FeedForward (FeedFor  (None, None, 32)    8352        ['Decoder-2-MultiHeadQueryAttenti\n",
            " ward)                                                           on-Norm[0][0]']                  \n",
            "                                                                                                  \n",
            " Decoder-2-FeedForward-Dropout   (None, None, 32)    0           ['Decoder-2-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Decoder-2-FeedForward-Add (Add  (None, None, 32)    0           ['Decoder-2-MultiHeadQueryAttenti\n",
            " )                                                               on-Norm[0][0]',                  \n",
            "                                                                  'Decoder-2-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Decoder-2-FeedForward-Norm (La  (None, None, 32)    64          ['Decoder-2-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Decoder-Output (EmbeddingSim)  (None, None, 77)     77          ['Decoder-2-FeedForward-Norm[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'Decoder-Token-Embedding[0][1]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 64,397\n",
            "Trainable params: 64,397\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "x = [np.array(encoder_input), np.array(decoder_input)]\n",
        "y = np.array(output_input)\n",
        "\n",
        "filename = \"/content/drive/My Drive/Models/english-spanish.h5\"\n",
        "\n",
        "history = model.fit(x, y, validation_split = 0.8, epochs = 100, batch_size = 32)\n",
        "model.save(filename)\n",
        "\n",
        "model.load_weights(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9s8_p50dICB",
        "outputId": "5cfc545b-24a8-404a-d95e-1f39400959a5"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 25s 581ms/step - loss: 0.9707 - val_loss: 0.9263\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.9100 - val_loss: 0.8808\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 0.8647 - val_loss: 0.8366\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.8221 - val_loss: 0.7960\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.7830 - val_loss: 0.7603\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 0.7495 - val_loss: 0.7305\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 0.7223 - val_loss: 0.7069\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 1s 151ms/step - loss: 0.7009 - val_loss: 0.6881\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.6830 - val_loss: 0.6752\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.6702 - val_loss: 0.6606\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 1s 119ms/step - loss: 0.6524 - val_loss: 0.6384\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.6305 - val_loss: 0.6175\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.6122 - val_loss: 0.6032\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 0.5958 - val_loss: 0.5804\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.5732 - val_loss: 0.5566\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 0.5503 - val_loss: 0.5375\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 1s 156ms/step - loss: 0.5320 - val_loss: 0.5195\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 1s 119ms/step - loss: 0.5138 - val_loss: 0.4988\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 0.4931 - val_loss: 0.4817\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.4802 - val_loss: 0.4634\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.4564 - val_loss: 0.4456\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 0.4395 - val_loss: 0.4253\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.4231 - val_loss: 0.4199\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.4102 - val_loss: 0.4004\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 0.3932 - val_loss: 0.3802\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.3749 - val_loss: 0.3620\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 0.3610 - val_loss: 0.3604\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 1s 121ms/step - loss: 0.3548 - val_loss: 0.3394\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 1s 117ms/step - loss: 0.3401 - val_loss: 0.3275\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.3251 - val_loss: 0.3142\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.3150 - val_loss: 0.3017\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.3012 - val_loss: 0.2868\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 0.2926 - val_loss: 0.2810\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.2794 - val_loss: 0.2690\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.2697 - val_loss: 0.2593\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 1s 121ms/step - loss: 0.2577 - val_loss: 0.2503\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 1s 128ms/step - loss: 0.2494 - val_loss: 0.2435\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 0.2407 - val_loss: 0.2308\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 1s 150ms/step - loss: 0.2315 - val_loss: 0.2238\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.2251 - val_loss: 0.2122\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 1s 126ms/step - loss: 0.2131 - val_loss: 0.2044\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 1s 130ms/step - loss: 0.2088 - val_loss: 0.2008\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 0.2011 - val_loss: 0.1921\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.1932 - val_loss: 0.1849\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 1s 124ms/step - loss: 0.1877 - val_loss: 0.1779\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 1s 121ms/step - loss: 0.1845 - val_loss: 0.1743\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 1s 122ms/step - loss: 0.1796 - val_loss: 0.1743\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 1s 130ms/step - loss: 0.1687 - val_loss: 0.1650\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 1s 155ms/step - loss: 0.1668 - val_loss: 0.1576\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 1s 121ms/step - loss: 0.1565 - val_loss: 0.1501\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 1s 122ms/step - loss: 0.1512 - val_loss: 0.1468\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.1472 - val_loss: 0.1437\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.1463 - val_loss: 0.1335\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 0.1361 - val_loss: 0.1295\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.1311 - val_loss: 0.1236\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 0.1263 - val_loss: 0.1202\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 0.1223 - val_loss: 0.1149\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.1154 - val_loss: 0.1115\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.1131 - val_loss: 0.1068\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 0.1117 - val_loss: 0.1104\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 0.1083 - val_loss: 0.0993\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0983 - val_loss: 0.0956\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.0942 - val_loss: 0.0914\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 0.0898 - val_loss: 0.0872\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0881 - val_loss: 0.0844\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 0.0835 - val_loss: 0.0843\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.0862 - val_loss: 0.0795\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 1s 125ms/step - loss: 0.0804 - val_loss: 0.0790\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 1s 123ms/step - loss: 0.0775 - val_loss: 0.0789\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.0752 - val_loss: 0.0748\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.0727 - val_loss: 0.0721\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 0.0706 - val_loss: 0.0660\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.0652 - val_loss: 0.0663\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.0638 - val_loss: 0.0638\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 0.0633 - val_loss: 0.0638\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0626 - val_loss: 0.0620\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.0585 - val_loss: 0.0583\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 1s 108ms/step - loss: 0.0567 - val_loss: 0.0557\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.0533 - val_loss: 0.0520\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.0525 - val_loss: 0.0514\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0492 - val_loss: 0.0470\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0475 - val_loss: 0.0468\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.0461 - val_loss: 0.0441\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 1s 116ms/step - loss: 0.0410 - val_loss: 0.0431\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 1s 123ms/step - loss: 0.0403 - val_loss: 0.0407\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 1s 123ms/step - loss: 0.0390 - val_loss: 0.0390\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 1s 112ms/step - loss: 0.0372 - val_loss: 0.0379\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0357 - val_loss: 0.0374\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0353 - val_loss: 0.0357\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.0336 - val_loss: 0.0344\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.0314 - val_loss: 0.0326\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.0302 - val_loss: 0.0322\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 1s 111ms/step - loss: 0.0305 - val_loss: 0.0313\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 1s 114ms/step - loss: 0.0295 - val_loss: 0.0310\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 1s 110ms/step - loss: 0.0285 - val_loss: 0.0280\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 1s 109ms/step - loss: 0.0277 - val_loss: 0.0295\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.0289 - val_loss: 0.0322\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.0289 - val_loss: 0.0267\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 0.0242 - val_loss: 0.0268\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 1s 119ms/step - loss: 0.0251 - val_loss: 0.0256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "z4jtYJ1ihoqR",
        "outputId": "ca5203d5-44d5-497d-aaf2-345123299cdf"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "  sentence = preprocess_text(sentence)\n",
        "  sentence_tokens = ['<START>'] + sentence.split(' ') + ['<END>', '<PAD>']\n",
        "  sentence_tokens = sentence_tokens + ['<PAD>'] * (max(source_max_len, target_max_len) - len(sentence_tokens))\n",
        "\n",
        "  tr_input = list(map(lambda x: source_token_dict[x], [tokens for tokens in sentence_tokens]))\n",
        "\n",
        "  decoded = decode(\n",
        "      model,\n",
        "      tr_input,\n",
        "      start_token = target_token_dict['<START>'],\n",
        "      end_token = target_token_dict['<END>'],\n",
        "      pad_token = target_token_dict['<PAD>']\n",
        "  )\n",
        "\n",
        "  code = ' '.join(map(lambda x: target_token_dict_inv[x], decoded[1:-1]))\n",
        "  code = preprocess_code_output(code)\n",
        "\n",
        "  return code"
      ],
      "metadata": {
        "id": "rrnS4WcXgo6M"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la exactitud [Correctas/Pruebas]\n",
        "import random\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "validation_set = random.sample(dataset, int(len(dataset) * 0.2))\n",
        "for element in validation_set:\n",
        "  element = element.split('\\t')\n",
        "  x.append(preprocess_text(element[0]))\n",
        "  y.append(preprocess_text(element[1]))\n",
        "\n",
        "x= list(map(lambda element: translate(element), x))\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "result = list(map(lambda a, b: a == b, x, y))\n",
        "\n",
        "count = 0\n",
        "for e in result:\n",
        "  if e == True:\n",
        "    count = count + 1\n",
        "\n",
        "print(count)\n",
        "print(len(result))\n",
        "\n",
        "exactitud = round(count / len(result), 2)\n",
        "print(\"La exactitud es de: {}\".format(exactitud))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQOHIBnkkwM9",
        "outputId": "ed49d7db-2539-4af9-b369-eded4ee9266e"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion1 ?ambulancia ) ) ( ambulancia-en-localizacion ?localizacion2 ?ambulancia ) ( ir ?localizacion2 ?localizacion1 )', 'ir ?localizacion1 -localizacionocalizacion ?localizacion2-localizacion', 'paciente1 paciente2-paciente', 'effect (and ( not ( llena-ambulancia ?paciente ) ) ( ambulancia-vacia ) )', 'paciente', 'paciente-en-localizacion', 'ir ?localizacion1 -localizacionocalizacion ?localizacion2-localizacion', 'hospital-en-localizacion', 'ir', 'paciente-en-localizacion localizacion4 paciente2', '?paciente-paciente', 'localizacion3', 'en', 'paciente-en-localizacion', 'precondition ( and ( ambulancia-vacia ) ( ambulancia-en-localizacion ?localizacion ?ambulancia ) )', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'paciente-en-localizacion localizacion3 paciente1', 'en', 'ambulancia-vacia', 'ir', 'paciente-en-localizacion', 'effect ( and ( not ( ambulancia-vacia ) ) ( llena-ambulancia ?paciente ) )', 'ambulancia-en-localizacion ?localizacion-localizacion ?ambulancia-ambulancia', 'ambulancia-vacia', 'paciente-en-localizacion', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'precondition ( and ( ambulancia ?localizacion1 ?ambulancia ) ( ir ?localizacion1 ?localizacion2 ) )', 'ambulancia-en-localizacion localizacion1 ambulancia1', 'en', 'paciente', 'ambulancia-en-localizacion localizacion1 ambulancia1', 'parameters', 'hospital1-hospital', 'paciente-en-localizacion', 'paciente-en-localizacion', 'hospital1-hospital', 'localizacion1', 'paciente-en-localizacion', 'ir localizacion1 localizacion2', 'ambulancia-en-localizacion', 'ir localizacion1 localizacion2', 'hospital-en-localizacion', 'paciente', 'hospital-en localizacion1', 'paciente1 paciente2-paciente', 'ambulancia1-ambulancia', 'effect', 'paciente-en-localizacion', 'en', 'hospital-en localizacion1', 'ambulancia1-ambulancia', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'ir ?localizacion1 -localizacionocalizacion ?localizacion2-localizacion', 'paciente-en-localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion1 ?ambulancia ) ) ( ambulancia-en-localizacion ?localizacion2 ?ambulancia ) ( ir ?localizacion2 ?localizacion1 )', 'types paciente', 'types', 'paciente-en-localizacion', 'hospital-en localizacion1', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'localizacion', 'en', 'ir localizacion1 localizacion2', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'precondition ( and ( llena-ambulancia ?paciente ) ( ambulancia-en-localizacion ?localizacion ?ambulancia ) )', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'en', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'paciente-en-localizacion', '?paciente-paciente', 'paciente-en-localizacion', 'types paciente ambulancia localizacion hospital', 'ambulancia1-ambulancia', 'types paciente ambulancia localizacion hospital', 'ambulancia1-ambulancia', 'paciente-en-localizacion', 'types paciente ambulancia localizacion hospital', 'paciente-en-localizacion', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'localizacion', 'hospital1-hospital', 'hospital-en-localizacion ?localizacion-localizacion ', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'ambulancia-vacia', 'paciente-en-localizacion', 'ambulancia-vacia', 'effect ( and ( not ( ambulancia-vacia ) ) ( llena-ambulancia ?paciente ) )', 'paciente1 paciente2-paciente', 'ir localizacion2 localizacion4', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion4 paciente2', 'ambulancia-vacia', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion4 paciente2', 'paciente-en-localizacion', 'paciente-en-localizacion', 'localizacion', 'types', '?ambulancia-ambulancia', 'hospital1-hospital', 'hospital1-hospital', 'paciente-en-localizacion', 'en', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente1 paciente2-paciente', 'ir localizacion1 localizacion2', 'ir localizacion2 localizacion4', 'paciente', 'precondition ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'effect (and ( not ( llena-ambulancia ?paciente ) ) ( ambulancia-vacia ) )', 'hospital1-hospital', 'effect ( and ( ambulancia-en-localizacion ?localizacion1 ?ambulancia ) ) ( ambulancia-en-localizacion ?localizacion2 ?ambulancia ) ( ir ?localizacion2 ?localizacion1 )', 'ambulancia1-ambulancia', 'paciente-en-localizacion localizacion4 paciente2', 'ambulancia1-ambulancia', 'ambulancia-vacia', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion4 paciente2', 'paciente-en-localizacion', 'hospital-en localizacion1', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'hospital1-hospital', 'effect ( and ( not ( ambulancia-vacia ) ) ( llena-ambulancia ?paciente ) )', 'localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'ambulancia-vacia', 'ir ?localizacion1 -localizacionocalizacion ?localizacion2-localizacion', 'paciente-en-localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'paciente-en-localizacion localizacion4 paciente2', 'ambulancia1-ambulancia', 'hospital-en localizacion1', 'ir localizacion2 localizacion4', 'effect ( and ( ambulancia-en-localizacion ?localizacion1 ?ambulancia ) ) ( ambulancia-en-localizacion ?localizacion2 ?ambulancia ) ( ir ?localizacion2 ?localizacion1 )', 'llena-ambulancia ?paciente-paciente', 'ir', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion3 paciente1', 'paciente-en-localizacion', 'ambulancia-en-localizacion localizacion1 ambulancia1', 'en', 'paciente-en-localizacion', 'types', 'types paciente ambulancia localizacion hospital', 'localizacion', 'llena-ambulancia', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'paciente', 'types', 'hospital1-hospital', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'ambulancia1-ambulancia', 'paciente', 'hospital1-hospital', 'localizacion', 'effect ( and ( not ( ambulancia-vacia ) ) ( llena-ambulancia ?paciente ) )', 'paciente-en-localizacion', 'effect', 'paciente-en-localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'precondition ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'paciente-en-localizacion', 'types', 'precondition ( and ( ambulancia ?localizacion1 ?ambulancia ) ( ir ?localizacion1 ?localizacion2 ) )', 'paciente-en-localizacion', 'localizacion1 localizacion2 localizacion3 localizacion4-localizacion', 'types paciente', 'localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion4 paciente2', 'paciente-en-localizacion', 'paciente-en-localizacion', 'ambulancia-en-localizacion localizacion1 ambulancia1', 'en', 'paciente', 'types paciente ambulancia localizacion hospital', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion3 paciente1', 'paciente-en-localizacion', 'ir localizacion2 localizacion4', 'parameters', 'paciente-en-localizacion', 'precondition ( and ( ambulancia ?localizacion1 ?ambulancia ) ( ir ?localizacion1 ?localizacion2 ) )', 'paciente-en-localizacion', 'paciente1 paciente2-paciente', 'hospital-en-localizacion', 'en']\n",
            "['effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion1 ?ambulancia ) ) ( ambulancia-en-localizacion ?localizacion2 ?ambulancia ) ( ir ?localizacion2 ?localizacion1 )', 'ir ?localizacion1 -localizacionocalizacion ?localizacion2 - localizacion', 'paciente1 paciente2 - paciente', 'effect (and ( not ( llena-ambulancia ?paciente ) ) ( ambulancia-vacia ) )', 'paciente', 'paciente-en-localizacion', 'ir ?localizacion1 -localizacionocalizacion ?localizacion2 - localizacion', 'hospital-en-localizacion', 'ir', 'paciente-en-localizacion localizacion4 paciente2', '?paciente - paciente', 'localizacion3', 'en', 'paciente-en-localizacion', 'precondition ( and ( ambulancia-vacia ) ( ambulancia-en-localizacion ?localizacion ?ambulancia ) )', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'paciente-en-localizacion localizacion3 paciente1', 'en', 'ambulancia-vacia', 'ir', 'paciente-en-localizacion', 'effect ( and ( not ( ambulancia-vacia ) ) ( llena-ambulancia ?paciente ) )', 'ambulancia-en-localizacion ?localizacion - localizacion ?ambulancia - ambulancia', 'ambulancia-vacia', 'paciente-en-localizacion ?localizacion - localizacion ?paciente - paciente', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'precondition ( and ( ambulancia ?localizacion1 ?ambulancia ) ( ir ?localizacion1 ?localizacion2 ) )', 'ambulancia-en-localizacion localizacion1 ambulancia1', 'en', 'paciente', 'ambulancia-en-localizacion localizacion1 ambulancia1', 'parameters', 'hospital1 - hospital', 'paciente-en-localizacion', 'paciente-en-localizacion', 'hospital1 - hospital', 'localizacion1', 'paciente-en-localizacion ?localizacion - localizacion ?paciente - paciente', 'ir localizacion1 localizacion2', 'ambulancia-en-localizacion', 'ir localizacion1 localizacion2', 'hospital-en-localizacion', 'paciente', 'hospital-en localizacion1', 'paciente1 paciente2 - paciente', 'ambulancia1 - ambulancia', 'effect', 'paciente-en-localizacion', 'en', 'hospital-en localizacion1', 'ambulancia1 - ambulancia', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'ir ?localizacion1 -localizacionocalizacion ?localizacion2 - localizacion', 'paciente-en-localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion1 ?ambulancia ) ) ( ambulancia-en-localizacion ?localizacion2 ?ambulancia ) ( ir ?localizacion2 ?localizacion1 )', 'types paciente', 'types', 'paciente-en-localizacion', 'hospital-en localizacion1', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'localizacion', 'en', 'ir localizacion1 localizacion2', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'precondition ( and ( llena-ambulancia ?paciente ) ( ambulancia-en-localizacion ?localizacion ?ambulancia ) )', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion', 'en', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'paciente-en-localizacion', '?paciente - paciente', 'paciente-en-localizacion', 'types paciente ambulancia localizacion hospital', 'ambulancia1 - ambulancia', 'types paciente ambulancia localizacion hospital', 'ambulancia1 - ambulancia', 'paciente-en-localizacion', 'types paciente ambulancia localizacion hospital', 'paciente-en-localizacion', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'localizacion', 'hospital1 - hospital', 'hospital-en-localizacion ?localizacion - localizacion ', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'ambulancia-vacia', 'paciente-en-localizacion', 'ambulancia-vacia', 'effect ( and ( not ( ambulancia-vacia ) ) ( llena-ambulancia ?paciente ) )', 'paciente1 paciente2 - paciente', 'ir localizacion2 localizacion4', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion4 paciente2', 'ambulancia-vacia', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion4 paciente2', 'paciente-en-localizacion', 'paciente-en-localizacion', 'localizacion', 'types', '?ambulancia - ambulancia', 'hospital1 - hospital', 'hospital1 - hospital', 'paciente-en-localizacion', 'en', 'paciente-en-localizacion', 'paciente-en-localizacion', 'paciente1 paciente2 - paciente', 'ir localizacion1 localizacion2', 'ir localizacion2 localizacion4', 'paciente', 'precondition ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'effect (and ( not ( llena-ambulancia ?paciente ) ) ( ambulancia-vacia ) )', 'hospital1 - hospital', 'effect ( and ( ambulancia-en-localizacion ?localizacion1 ?ambulancia ) ) ( ambulancia-en-localizacion ?localizacion2 ?ambulancia ) ( ir ?localizacion2 ?localizacion1 )', 'ambulancia1 - ambulancia', 'paciente-en-localizacion localizacion4 paciente2', 'ambulancia1 - ambulancia', 'ambulancia-vacia', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion4 paciente2', 'paciente-en-localizacion', 'hospital-en localizacion1', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'hospital1 - hospital', 'effect ( and ( not ( ambulancia-vacia ) ) ( llena-ambulancia ?paciente ) )', 'localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'ambulancia-vacia', 'ir ?localizacion1 -localizacionocalizacion ?localizacion2 - localizacion', 'paciente-en-localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'paciente-en-localizacion localizacion4 paciente2', 'ambulancia1 - ambulancia', 'hospital-en localizacion1', 'ir localizacion2 localizacion4', 'effect ( and ( ambulancia-en-localizacion ?localizacion1 ?ambulancia ) ) ( ambulancia-en-localizacion ?localizacion2 ?ambulancia ) ( ir ?localizacion2 ?localizacion1 )', 'llena-ambulancia ?paciente - paciente', 'ir', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion3 paciente1', 'paciente-en-localizacion', 'ambulancia-en-localizacion localizacion1 ambulancia1', 'en', 'paciente-en-localizacion', 'types', 'types paciente ambulancia localizacion hospital', 'localizacion', 'llena-ambulancia', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'paciente', 'types', 'hospital1 - hospital', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'ambulancia1 - ambulancia', 'paciente', 'hospital1 - hospital', 'localizacion', 'effect ( and ( not ( ambulancia-vacia ) ) ( llena-ambulancia ?paciente ) )', 'paciente-en-localizacion', 'effect', 'paciente-en-localizacion', 'effect ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'precondition ( and ( ambulancia-en-localizacion ?localizacion ?ambulancia ) ( paciente-en-localizacion ?localizacion ?paciente ) )', 'paciente-en-localizacion', 'types', 'precondition ( and ( ambulancia ?localizacion1 ?ambulancia ) ( ir ?localizacion1 ?localizacion2 ) )', 'paciente-en-localizacion', 'localizacion1 localizacion2 localizacion3 localizacion4 - localizacion', 'types paciente', 'localizacion', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion4 paciente2', 'paciente-en-localizacion', 'paciente-en-localizacion', 'ambulancia-en-localizacion localizacion1 ambulancia1', 'en', 'paciente', 'types paciente ambulancia localizacion hospital', 'paciente-en-localizacion', 'paciente-en-localizacion localizacion3 paciente1', 'paciente-en-localizacion', 'ir localizacion2 localizacion4', 'parameters', 'paciente-en-localizacion', 'precondition ( and ( ambulancia ?localizacion1 ?ambulancia ) ( ir ?localizacion1 ?localizacion2 ) )', 'paciente-en-localizacion', 'paciente1 paciente2 - paciente', 'hospital-en-localizacion', 'en']\n",
            "158\n",
            "201\n",
            "La exactitud es de: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate('el paciente se encuentra en localización')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QEba1mNJkNMH",
        "outputId": "89d3957b-1cc1-4103-db41-59f09072a6f6"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'paciente-en-localizacion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    }
  ]
}